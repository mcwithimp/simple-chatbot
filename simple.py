import json

import boto3
import requests  # HTTP ìš”ì²­ ìƒì„±ì„ ìœ„í•œ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import streamlit as st  # Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸í•˜ì—¬ ì›¹ ì•± ìƒì„±

# Bedrock runtime
bedrock_runtime = boto3.client(service_name="bedrock-runtime", region_name="us-east-1")

# ì›¹ ì•± ì œëª© ì„¤ì •
st.title("Chatbot powered by Bedrock")

# ì„¸ì…˜ ìƒíƒœì— ë©”ì‹œì§€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "inputTokenCount" not in st.session_state:
    st.session_state.inputTokenCount = 0

if "outputTokenCount" not in st.session_state:
    st.session_state.outputTokenCount = 0

# ì„¸ì…˜ ìƒíƒœì— ì €ì¥ëœ ë©”ì‹œì§€ ìˆœíšŒí•˜ë©° í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):  # ì±„íŒ… ë©”ì‹œì§€ ë²„ë¸” ìƒì„±
        st.markdown(message["content"])  # ë©”ì‹œì§€ ë‚´ìš© ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë Œë”ë§


def chunk_handler(chunk):
    #  APIê°€ ì„œë¡œ ë‹¤ë¥¸ íƒ€ì…ì„ ë¦¬í„´
    # print(f"\n\n!!!\n{chunk}")
    text = None
    chunk_type = chunk.get("type")
    if chunk_type == "content_block_start":
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì‹œì‘
        text = chunk["content_block"]["text"]
    elif chunk_type == "content_block_delta":
        # ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ ì‘ë‹µ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€
        text = chunk["delta"]["text"]
    elif chunk_type == "message_stop":
        # ìš”ì²­ì— ëŒ€í•œ ë©”íŠ¸ë¦­ì„ í¬í•¨
        metric = chunk["amazon-bedrock-invocationMetrics"]
        st.session_state.inputTokenCount = (
            st.session_state.inputTokenCount + metric["inputTokenCount"]
        )
        st.session_state.outputTokenCount = (
            st.session_state.outputTokenCount + metric["outputTokenCount"]
        )
        text = None
    else:
        text = None

    if text is not None:
        print(text, end="")
    return text


def get_streaming_response(prompt):
    body = {
        "anthropic_version": "bedrock-2023-05-31",
        "max_tokens": 1000,
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": prompt}],
            }
        ],
    }
    jsonBody = json.dumps(body)

    # stream
    response = bedrock_runtime.invoke_model_with_response_stream(
        modelId="anthropic.claude-3-sonnet-20240229-v1:0",
        body=jsonBody,
    )
    stream = response.get("body")

    if stream:
        for event in stream:  # ìŠ¤íŠ¸ë¦¼ì—ì„œ ë°˜í™˜ëœ ê° ì´ë²¤íŠ¸ ì²˜ë¦¬
            chunk = event.get("chunk")
            if chunk:
                chunk_json = json.loads(chunk.get("bytes").decode())
                text = chunk_handler(chunk_json)
                if text is not None:
                    yield text


# ì‚¬ìš©ìë¡œë¶€í„° ì…ë ¥ ë°›ìŒ
if prompt := st.chat_input("Message Bedrock..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):  # ì‚¬ìš©ì ë©”ì‹œì§€ ì±„íŒ… ë©”ì‹œì§€ ë²„ë¸” ìƒì„±
        st.markdown(prompt)  # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ

    with st.chat_message("assistant"):  # ë³´ì¡° ë©”ì‹œì§€ ì±„íŒ… ë©”ì‹œì§€ ë²„ë¸” ìƒì„±
        with st.spinner("AI ì‘ë‹µ ìƒì„±ì¤‘..."):
            model_output = st.write_stream(get_streaming_response(prompt))

    inputPrice = st.session_state.inputTokenCount / 1000 * 0.003
    outputPrice = st.session_state.outputTokenCount / 1000 * 0.015
    st.toast(f"{inputPrice + outputPrice} USD used", icon="ğŸ’°")
    # ë³´ì¡° ì‘ë‹µ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    st.session_state.messages.append({"role": "assistant", "content": model_output})
